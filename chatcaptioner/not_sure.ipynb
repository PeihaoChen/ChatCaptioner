{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44a676-0233-4475-bb98-a81fac693899",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03947bd6-59ca-4b9c-a30b-33dbeea8fc54",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import csv\n",
    "import yaml\n",
    "from chatcaptioner.chat import get_chat_log\n",
    "from chatcaptioner.blip2 import Blip2\n",
    "from chatcaptioner.utils import print_info, plot_img, extractQA_chatgpt, RandomSampledDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4088d-3886-43e0-9dc9-0a8b9b946fae",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# specify SAVE_PATH to visualize the result you want\n",
    "SAVE_PATH = 'experiments/testV4_chatgpt/'\n",
    "DATA_ROOT = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16026ee-aa9b-436e-be6d-d4cc48172214",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "blip2 = Blip2('FlanT5 XXL', device_id=0, bit8=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba38f95-3768-4b26-8881-e5693c65a13e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets_list = os.listdir(SAVE_PATH)\n",
    "datasets_list = ['cc_val']\n",
    "uncertainty_list = []\n",
    "\n",
    "for dataset_name in datasets_list:\n",
    "    print('============================')\n",
    "    print('          {}          '.format(dataset_name))\n",
    "    print('============================')\n",
    "    dataset = RandomSampledDataset(DATA_ROOT, dataset_name)\n",
    "    \n",
    "    save_infos = glob(os.path.join(SAVE_PATH, dataset_name, 'caption_result', '*'))\n",
    "    for info_file in save_infos:\n",
    "        with open(info_file, 'r') as f:\n",
    "            info = yaml.safe_load(f)\n",
    "        img_id = info['id'] if 'id' in info else info['setting']['id']\n",
    "        test_img, _ = dataset.fetch_img(img_id)\n",
    "        \n",
    "        chat = info['FlanT5 XXL']['ChatCaptioner']['chat']\n",
    "        questions, answers = extractQA_chatgpt(chat)\n",
    "        not_sure = False\n",
    "        for q, a in zip(questions, answers):\n",
    "            if 'sure' in a or 'know' in a:\n",
    "                not_sure = True\n",
    "                print('Question: {}'.format(q))\n",
    "                print('Answer: {}'.format(a))\n",
    "                uncertainty_list.append((img_id, q, a))\n",
    "        if not_sure:\n",
    "            plot_img(test_img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717d01e-fbfc-44b3-8690-542d417a8c26",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_dict = {}\n",
    "for img_id, q, a in uncertainty_list:\n",
    "    if img_id not in uncertainty_dict:\n",
    "        uncertainty_dict[img_id] = [q]\n",
    "    else:\n",
    "        uncertainty_dict[img_id].append(q)\n",
    "with open(os.path.join('not_sure.yaml'), 'w') as f:\n",
    "    yaml.dump(uncertainty_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422228e3-700c-43cf-a857-a9a4871ce714",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32c46f-1f94-4b01-8ea5-92f72619d975",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_dict['13778']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268f88d-bdeb-4e5e-9cf7-c5046e2cbf35",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "info_file = os.path.join(SAVE_PATH, dataset_name, 'caption_result', '13276.yaml')\n",
    "with open(info_file, 'r') as f:\n",
    "    info = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dbf33-cf00-4ecd-b740-ba89332ce74d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "questions, orig_answers = extractQA_chatgpt(info['FlanT5 XXL']['ChatCaptioner']['chat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad489b-610a-4750-be7c-6d058eb3ab8e",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a294b74-8a12-4a80-a536-68442520dd80",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "orig_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780d875-3998-4337-bdab-b7769c43cde0",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ANSWER_INSTRUCTION = 'Answer given questions. If you are not sure about the answer, say you don\\'t know honestly. Don\\'t imagine any contents that are not in the image.'\n",
    "ANSWER_INSTRUCTION = 'Answer given questions. Don\\'t imagine any contents that are not in the image.'\n",
    "SUB_ANSWER_INSTRUCTION = 'Answer: '  # template following blip2 huggingface demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de5f91-1239-455e-826a-5314eb901fa5",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i in range(len(questions)):\n",
    "    print('Question: {}'.format(questions[i]))\n",
    "    blip2_prompt = '\\n'.join([ANSWER_INSTRUCTION, \n",
    "                              get_chat_log(questions[:i+1], answers, last_n=1), \n",
    "                              SUB_ANSWER_INSTRUCTION])    \n",
    "    answer = blip2.ask(test_img, blip2_prompt)\n",
    "    answer = answer.split('Question:')[0].replace('\\n', ' ').strip()\n",
    "    print('Answer: {}'.format(answer))\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8750fb-3022-4f99-88ee-5fb385988a69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open('h_uncertain.csv', 'r') as csvfile:\n",
    "    # Create a CSV reader object\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in csvreader:\n",
    "        # Access the values in the row by index\n",
    "        img_id = row['Input.image_id']\n",
    "        question = row['Input.question']\n",
    "        tag = img_id + '_' + question\n",
    "        answer = row['Answer.summary']\n",
    "        \n",
    "        if tag not in results:\n",
    "            results[tag] = [answer]\n",
    "        else:\n",
    "            results[tag].append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5a762-4be8-4041-8287-5c652f8bb3c5",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5edbf0-d9a9-4638-85ec-db9906512a10",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uncertainQ = []\n",
    "certainQ = []\n",
    "for tag, answers in results.items():\n",
    "    n_none = 0\n",
    "    for answer in answers:\n",
    "        if 'none' in answer.lower():\n",
    "            n_none += 1\n",
    "    if n_none >= 2:\n",
    "        uncertainQ.append(tag)\n",
    "    else:\n",
    "        certainQ.append([tag, answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3fc0f-1654-4287-ba12-60eb328b0295",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "certain_img = {}\n",
    "for tag, h_answers in certainQ:\n",
    "    img_id, question = tag.split('_')\n",
    "    if img_id in certain_img:\n",
    "        certain_img[img_id][question] = h_answers\n",
    "    else:\n",
    "        certain_img[img_id] = {question: h_answers}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b78acd-a1c7-47a2-a4a9-ad529f2dd352",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(certainQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8aca85-2b44-4022-bc10-bd7f83eb9510",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ANSWER_INSTRUCTION = 'Answer given questions. Don\\'t imagine any contents that are not in the image.'\n",
    "SUB_ANSWER_INSTRUCTION = 'Answer: '  # template following blip2 huggingface demo\n",
    "\n",
    "for img_id, c_questions in certain_img.items():\n",
    "    with open(os.path.join(SAVE_PATH, dataset_name, 'caption_result', '{}.yaml'.format(img_id)), 'r') as f:\n",
    "        info = yaml.safe_load(f)\n",
    "    test_img, _ = dataset.fetch_img(img_id)\n",
    "\n",
    "    chat = info['FlanT5 XXL']['ChatCaptioner']['chat']\n",
    "    questions, _ = extractQA_chatgpt(chat)\n",
    "\n",
    "    answers = []\n",
    "    for i in range(len(questions)):\n",
    "        if questions[i] in c_questions:\n",
    "            print('?????????????????')\n",
    "        print('Question: {}'.format(questions[i]))\n",
    "        blip2_prompt = '\\n'.join([ANSWER_INSTRUCTION, \n",
    "                                  get_chat_log(questions[:i+1], answers, last_n=1), \n",
    "                                  SUB_ANSWER_INSTRUCTION])    \n",
    "        answer = blip2.ask(test_img, blip2_prompt)\n",
    "        answer = answer.split('Question:')[0].replace('\\n', ' ').strip()\n",
    "        answers.append(answer)\n",
    "        print('Answer: {}'.format(answer))\n",
    "        if questions[i] in c_questions:\n",
    "            for h_answer in c_questions[questions[i]]:\n",
    "                print('Human: {}'.format(h_answer))\n",
    "            print('!!!!!!!!!!!!!!!!!!!!')\n",
    "    plot_img(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a9d64-638b-4861-90e0-fe1479b60a1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatae",
   "language": "python",
   "name": "chatae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}